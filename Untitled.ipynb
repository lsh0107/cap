{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de92c056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import re\n",
    "import glob, os\n",
    "from ckonlpy.tag import Twitter\n",
    "from konlpy.tag import Kkma, Okt\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from pyclustering.cluster import kmedoids\n",
    "from collections import Counter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ea3ecb94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Desktop\\4-2\\cd2\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = os.getcwd()\n",
    "print(BASE_DIR)\n",
    "senti = pd.read_csv(BASE_DIR + '/ratings.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d057b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8112052</td>\n",
       "      <td>ì–´ë¦´ë•Œë³´ê³  ì§€ê¸ˆë‹¤ì‹œë´ë„ ì¬ë°Œì–´ìš”ã…‹ã…‹</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8132799</td>\n",
       "      <td>ë””ìì¸ì„ ë°°ìš°ëŠ” í•™ìƒìœ¼ë¡œ, ì™¸êµ­ë””ìì´ë„ˆì™€ ê·¸ë“¤ì´ ì¼êµ° ì „í†µì„ í†µí•´ ë°œì „í•´ê°€ëŠ” ë¬¸í™”ì‚°...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4655635</td>\n",
       "      <td>í´ë¦¬ìŠ¤ìŠ¤í† ë¦¬ ì‹œë¦¬ì¦ˆëŠ” 1ë¶€í„° ë‰´ê¹Œì§€ ë²„ë¦´ê»˜ í•˜ë‚˜ë„ ì—†ìŒ.. ìµœê³ .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9251303</td>\n",
       "      <td>ì™€.. ì—°ê¸°ê°€ ì§„ì§œ ê°œì©”êµ¬ë‚˜.. ì§€ë£¨í• ê±°ë¼ê³  ìƒê°í–ˆëŠ”ë° ëª°ì…í•´ì„œ ë´¤ë‹¤.. ê·¸ë˜ ì´ëŸ°...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10067386</td>\n",
       "      <td>ì•ˆê°œ ììš±í•œ ë°¤í•˜ëŠ˜ì— ë–  ìˆëŠ” ì´ˆìŠ¹ë‹¬ ê°™ì€ ì˜í™”.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>8963373</td>\n",
       "      <td>í¬ì¼“ ëª¬ìŠ¤í„° ì§œê°€ ã…¡ã…¡;;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>3302770</td>\n",
       "      <td>ì“°.ë ˆ.ê¸°</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>5458175</td>\n",
       "      <td>ì™„ì „ ì‚¬ì´ì½”ì˜í™”. ë§ˆì§€ë§‰ì€ ë”ìš±ë” ì´ ì˜í™”ì˜ì§ˆì„ ë–¨ì–´íŠ¸ë¦°ë‹¤.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>6908648</td>\n",
       "      <td>ì™œë‚œ ì¬ë¯¸ì—†ì—ˆì§€ ã… ã…  ë¼ë”°ëšœì´ ë³´ê³ ë‚˜ì„œ ìŠ¤ë¨¸í”„ ë´ì„œ ê·¸ëŸ°ê°€ ã…‹ã…‹</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>8548411</td>\n",
       "      <td>í¬í’ì €ê·¸ê°€ë‚˜ê°€ì‹ ë‹¤ì˜ì°¨ì˜ì°¨ì˜ì°¨</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                           document  label\n",
       "0        8112052                                ì–´ë¦´ë•Œë³´ê³  ì§€ê¸ˆë‹¤ì‹œë´ë„ ì¬ë°Œì–´ìš”ã…‹ã…‹      1\n",
       "1        8132799  ë””ìì¸ì„ ë°°ìš°ëŠ” í•™ìƒìœ¼ë¡œ, ì™¸êµ­ë””ìì´ë„ˆì™€ ê·¸ë“¤ì´ ì¼êµ° ì „í†µì„ í†µí•´ ë°œì „í•´ê°€ëŠ” ë¬¸í™”ì‚°...      1\n",
       "2        4655635               í´ë¦¬ìŠ¤ìŠ¤í† ë¦¬ ì‹œë¦¬ì¦ˆëŠ” 1ë¶€í„° ë‰´ê¹Œì§€ ë²„ë¦´ê»˜ í•˜ë‚˜ë„ ì—†ìŒ.. ìµœê³ .      1\n",
       "3        9251303  ì™€.. ì—°ê¸°ê°€ ì§„ì§œ ê°œì©”êµ¬ë‚˜.. ì§€ë£¨í• ê±°ë¼ê³  ìƒê°í–ˆëŠ”ë° ëª°ì…í•´ì„œ ë´¤ë‹¤.. ê·¸ë˜ ì´ëŸ°...      1\n",
       "4       10067386                        ì•ˆê°œ ììš±í•œ ë°¤í•˜ëŠ˜ì— ë–  ìˆëŠ” ì´ˆìŠ¹ë‹¬ ê°™ì€ ì˜í™”.      1\n",
       "...          ...                                                ...    ...\n",
       "199995   8963373                                     í¬ì¼“ ëª¬ìŠ¤í„° ì§œê°€ ã…¡ã…¡;;      0\n",
       "199996   3302770                                              ì“°.ë ˆ.ê¸°      0\n",
       "199997   5458175                  ì™„ì „ ì‚¬ì´ì½”ì˜í™”. ë§ˆì§€ë§‰ì€ ë”ìš±ë” ì´ ì˜í™”ì˜ì§ˆì„ ë–¨ì–´íŠ¸ë¦°ë‹¤.      0\n",
       "199998   6908648                ì™œë‚œ ì¬ë¯¸ì—†ì—ˆì§€ ã… ã…  ë¼ë”°ëšœì´ ë³´ê³ ë‚˜ì„œ ìŠ¤ë¨¸í”„ ë´ì„œ ê·¸ëŸ°ê°€ ã…‹ã…‹      0\n",
       "199999   8548411                                    í¬í’ì €ê·¸ê°€ë‚˜ê°€ì‹ ë‹¤ì˜ì°¨ì˜ì°¨ì˜ì°¨      0\n",
       "\n",
       "[200000 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e31af73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\admin\\\\Desktop\\\\4-2\\\\cd2'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f5dd4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(BASE_DIR + '/test.txt', sep='\\t')\n",
    "df_train = pd.read_csv(BASE_DIR + '/train.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b6de8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['document'].nunique(), df_train['label'].nunique()\n",
    "df_train.drop_duplicates(subset=['document'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "108bc5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.dropna(how = 'any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05a5a019",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp/ipykernel_22692/1677612632.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_train['document'] = df_train['document'].str.replace(\"[^ã„±-ã…ã…-ã…£ê°€-í£ ]\",\"\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>ì•„ ë”ë¹™ ì§„ì§œ ì§œì¦ë‚˜ë„¤ìš” ëª©ì†Œë¦¬</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>í í¬ìŠ¤í„°ë³´ê³  ì´ˆë”©ì˜í™”ì¤„ì˜¤ë²„ì—°ê¸°ì¡°ì°¨ ê°€ë³ì§€ ì•Šêµ¬ë‚˜</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>ë„ˆë¬´ì¬ë°“ì—ˆë‹¤ê·¸ë˜ì„œë³´ëŠ”ê²ƒì„ì¶”ì²œí•œë‹¤</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>êµë„ì†Œ ì´ì•¼ê¸°êµ¬ë¨¼ ì†”ì§íˆ ì¬ë¯¸ëŠ” ì—†ë‹¤í‰ì  ì¡°ì •</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>ì‚¬ì´ëª¬í˜ê·¸ì˜ ìµì‚´ìŠ¤ëŸ° ì—°ê¸°ê°€ ë‹ë³´ì˜€ë˜ ì˜í™”ìŠ¤íŒŒì´ë”ë§¨ì—ì„œ ëŠ™ì–´ë³´ì´ê¸°ë§Œ í–ˆë˜ ì»¤ìŠ¤í‹´ ë˜...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                  ì•„ ë”ë¹™ ì§„ì§œ ì§œì¦ë‚˜ë„¤ìš” ëª©ì†Œë¦¬      0\n",
       "1   3819312                         í í¬ìŠ¤í„°ë³´ê³  ì´ˆë”©ì˜í™”ì¤„ì˜¤ë²„ì—°ê¸°ì¡°ì°¨ ê°€ë³ì§€ ì•Šêµ¬ë‚˜      1\n",
       "2  10265843                                  ë„ˆë¬´ì¬ë°“ì—ˆë‹¤ê·¸ë˜ì„œë³´ëŠ”ê²ƒì„ì¶”ì²œí•œë‹¤      0\n",
       "3   9045019                          êµë„ì†Œ ì´ì•¼ê¸°êµ¬ë¨¼ ì†”ì§íˆ ì¬ë¯¸ëŠ” ì—†ë‹¤í‰ì  ì¡°ì •      0\n",
       "4   6483659  ì‚¬ì´ëª¬í˜ê·¸ì˜ ìµì‚´ìŠ¤ëŸ° ì—°ê¸°ê°€ ë‹ë³´ì˜€ë˜ ì˜í™”ìŠ¤íŒŒì´ë”ë§¨ì—ì„œ ëŠ™ì–´ë³´ì´ê¸°ë§Œ í–ˆë˜ ì»¤ìŠ¤í‹´ ë˜...      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['document'] = df_train['document'].str.replace(\"[^ã„±-ã…ã…-ã…£ê°€-í£ ]\",\"\")\n",
    "df_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "518e33ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp/ipykernel_22692/2419574225.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_train['document'] = df_train['document'].str.replace('^ +', \"\") # white space ë°ì´í„°ë¥¼ empty valueë¡œ ë³€ê²½\n"
     ]
    }
   ],
   "source": [
    "df_train['document'] = df_train['document'].str.replace('^ +', \"\") # white space ë°ì´í„°ë¥¼ empty valueë¡œ ë³€ê²½\n",
    "df_train['document'].replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e4da99e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>4221289</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>9509970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>10147571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>7117896</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>6478189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id document  label\n",
       "404   4221289      NaN      0\n",
       "412   9509970      NaN      1\n",
       "470  10147571      NaN      1\n",
       "584   7117896      NaN      0\n",
       "593   6478189      NaN      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[df_train.document.isnull()][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4701a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.dropna(how = 'any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b483f16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp/ipykernel_22692/2602539837.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_test['document'] = df_test['document'].str.replace(\"[^ã„±-ã…ã…-ã…£ê°€-í£ ]\",\"\") # ì •ê·œ í‘œí˜„ì‹ ìˆ˜í–‰\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp/ipykernel_22692/2602539837.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_test['document'] = df_test['document'].str.replace('^ +', \"\") # ê³µë°±ì€ empty ê°’ìœ¼ë¡œ ë³€ê²½\n"
     ]
    }
   ],
   "source": [
    "df_test.drop_duplicates(subset = ['document'], inplace=True) # document ì—´ì—ì„œ ì¤‘ë³µì¸ ë‚´ìš©ì´ ìˆë‹¤ë©´ ì¤‘ë³µ ì œê±°\n",
    "df_test['document'] = df_test['document'].str.replace(\"[^ã„±-ã…ã…-ã…£ê°€-í£ ]\",\"\") # ì •ê·œ í‘œí˜„ì‹ ìˆ˜í–‰\n",
    "df_test['document'] = df_test['document'].str.replace('^ +', \"\") # ê³µë°±ì€ empty ê°’ìœ¼ë¡œ ë³€ê²½\n",
    "df_test['document'].replace('', np.nan, inplace=True) # ê³µë°±ì€ Null ê°’ìœ¼ë¡œ ë³€ê²½\n",
    "df_test = df_test.dropna(how='any') # Null ê°’ ì œê±°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55008c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(BASE_DIR + '/train.csv', encoding='utf-8-sig', index=False)\n",
    "df_test.to_csv(BASE_DIR + '/test.csv', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6ced3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(BASE_DIR + '/test.csv')\n",
    "df_train = pd.read_csv(BASE_DIR + '/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37514b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = pd.read_csv(\"https://raw.githubusercontent.com/yoonkt200/FastCampusDataset/master/korean_stopwords.txt\").values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d230b52b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ì˜¤ë‹¤', 'ì´ë ‡ë‹¤', 'ê²ƒ', 'ë„', 'ì˜í™”', 'ë¼ê³ ', 'ì°¨ë¼ë¦¬', 'ë®¤ì§ë¹„ë””ì˜¤', 'ë¥¼', 'ë§Œë“¤ë‹¤', 'ê²Œ', 'ë‚˜ë‹¤', 'ë»”']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okt = Okt()\n",
    "okt.morphs('ì™€ ì´ëŸ° ê²ƒë„ ì˜í™”ë¼ê³  ì°¨ë¼ë¦¬ ë®¤ì§ë¹„ë””ì˜¤ë¥¼ ë§Œë“œëŠ” ê²Œ ë‚˜ì„ ë»”', stem = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9f2eb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 145393/145393 [04:48<00:00, 504.48it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "for sentence in tqdm(df_train['document']):\n",
    "    tokenized_sentence = okt.morphs(sentence, stem=True) # í† í°í™”\n",
    "    stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords] # ë¶ˆìš©ì–´ ì œê±°\n",
    "    X_train.append(stopwords_removed_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64e6ca01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48852/48852 [01:47<00:00, 456.48it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test = []\n",
    "for sentence in tqdm(df_test['document']):\n",
    "    tokenized_sentence = okt.morphs(sentence, stem=True) # í† í°í™”\n",
    "    stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords] # ë¶ˆìš©ì–´ ì œê±°\n",
    "    X_test.append(stopwords_removed_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b215d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "448aa2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë‹¨ì–´ ì§‘í•©(vocabulary)ì˜ í¬ê¸° : 43770\n",
      "ë“±ì¥ ë¹ˆë„ê°€ 2ë²ˆ ì´í•˜ì¸ í¬ê·€ ë‹¨ì–´ì˜ ìˆ˜: 24337\n",
      "ë‹¨ì–´ ì§‘í•©ì—ì„œ í¬ê·€ ë‹¨ì–´ì˜ ë¹„ìœ¨: 55.60201050948138\n",
      "ì „ì²´ ë“±ì¥ ë¹ˆë„ì—ì„œ í¬ê·€ ë‹¨ì–´ ë“±ì¥ ë¹ˆë„ ë¹„ìœ¨: 1.571480691144935\n"
     ]
    }
   ],
   "source": [
    "threshold = 3\n",
    "total_cnt = len(tokenizer.word_index) # ë‹¨ì–´ì˜ ìˆ˜\n",
    "rare_cnt = 0 # ë“±ì¥ ë¹ˆë„ìˆ˜ê°€ thresholdë³´ë‹¤ ì‘ì€ ë‹¨ì–´ì˜ ê°œìˆ˜ë¥¼ ì¹´ìš´íŠ¸\n",
    "total_freq = 0 # í›ˆë ¨ ë°ì´í„°ì˜ ì „ì²´ ë‹¨ì–´ ë¹ˆë„ìˆ˜ ì´ í•©\n",
    "rare_freq = 0 # ë“±ì¥ ë¹ˆë„ìˆ˜ê°€ thresholdë³´ë‹¤ ì‘ì€ ë‹¨ì–´ì˜ ë“±ì¥ ë¹ˆë„ìˆ˜ì˜ ì´ í•©\n",
    "\n",
    "# ë‹¨ì–´ì™€ ë¹ˆë„ìˆ˜ì˜ ìŒ(pair)ì„ keyì™€ valueë¡œ ë°›ëŠ”ë‹¤.\n",
    "for key, value in tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # ë‹¨ì–´ì˜ ë“±ì¥ ë¹ˆë„ìˆ˜ê°€ thresholdë³´ë‹¤ ì‘ìœ¼ë©´\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('ë‹¨ì–´ ì§‘í•©(vocabulary)ì˜ í¬ê¸° :',total_cnt)\n",
    "print('ë“±ì¥ ë¹ˆë„ê°€ %së²ˆ ì´í•˜ì¸ í¬ê·€ ë‹¨ì–´ì˜ ìˆ˜: %s'%(threshold - 1, rare_cnt))\n",
    "print(\"ë‹¨ì–´ ì§‘í•©ì—ì„œ í¬ê·€ ë‹¨ì–´ì˜ ë¹„ìœ¨:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"ì „ì²´ ë“±ì¥ ë¹ˆë„ì—ì„œ í¬ê·€ ë‹¨ì–´ ë“±ì¥ ë¹ˆë„ ë¹„ìœ¨:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e4d1078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë‹¨ì–´ ì§‘í•©ì˜ í¬ê¸° : 19434\n"
     ]
    }
   ],
   "source": [
    "# ì „ì²´ ë‹¨ì–´ ê°œìˆ˜ ì¤‘ ë¹ˆë„ìˆ˜ 2ì´í•˜ì¸ ë‹¨ì–´ëŠ” ì œê±°.\n",
    "# 0ë²ˆ íŒ¨ë”© í† í°ì„ ê³ ë ¤í•˜ì—¬ + 1\n",
    "vocab_size = total_cnt - rare_cnt + 1\n",
    "print('ë‹¨ì–´ ì§‘í•©ì˜ í¬ê¸° :',vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9b3d382",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(vocab_size) \n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af21a44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(df_train['label'])\n",
    "y_test = np.array(df_train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1aa2929",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_train = [index for index, sentence in enumerate(X_train) if len(sentence) < 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c0020dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145181\n",
      "145181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.delete(X_train, drop_train, axis=0)\n",
    "y_train = np.delete(y_train, drop_train, axis=0)\n",
    "print(len(X_train))\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "adc80ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "    count = 0\n",
    "    for sentence in nested_list:\n",
    "        if(len(sentence) <= max_len):\n",
    "            count = count + 1\n",
    "    print('ì „ì²´ ìƒ˜í”Œ ì¤‘ ê¸¸ì´ê°€ %s ì´í•˜ì¸ ìƒ˜í”Œì˜ ë¹„ìœ¨: %s'%(max_len, (count / len(nested_list))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c6da045e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì „ì²´ ìƒ˜í”Œ ì¤‘ ê¸¸ì´ê°€ 30 ì´í•˜ì¸ ìƒ˜í”Œì˜ ë¹„ìœ¨: 91.6194267844966\n"
     ]
    }
   ],
   "source": [
    "max_len = 30\n",
    "below_threshold_len(max_len, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "20256dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e35bcda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1814/1815 [============================>.] - ETA: 0s - loss: 0.3896 - acc: 0.8221\n",
      "Epoch 1: val_acc improved from -inf to 0.84420, saving model to best_model.h5\n",
      "1815/1815 [==============================] - 46s 25ms/step - loss: 0.3897 - acc: 0.8221 - val_loss: 0.3528 - val_acc: 0.8442\n",
      "Epoch 2/10\n",
      "1814/1815 [============================>.] - ETA: 0s - loss: 0.3276 - acc: 0.8566\n",
      "Epoch 2: val_acc improved from 0.84420 to 0.85178, saving model to best_model.h5\n",
      "1815/1815 [==============================] - 44s 24ms/step - loss: 0.3276 - acc: 0.8566 - val_loss: 0.3426 - val_acc: 0.8518\n",
      "Epoch 3/10\n",
      "1814/1815 [============================>.] - ETA: 0s - loss: 0.3025 - acc: 0.8705\n",
      "Epoch 3: val_acc improved from 0.85178 to 0.86131, saving model to best_model.h5\n",
      "1815/1815 [==============================] - 45s 25ms/step - loss: 0.3025 - acc: 0.8705 - val_loss: 0.3259 - val_acc: 0.8613\n",
      "Epoch 4/10\n",
      "1815/1815 [==============================] - ETA: 0s - loss: 0.2834 - acc: 0.8817\n",
      "Epoch 4: val_acc did not improve from 0.86131\n",
      "1815/1815 [==============================] - 46s 25ms/step - loss: 0.2834 - acc: 0.8817 - val_loss: 0.3385 - val_acc: 0.8533\n",
      "Epoch 5/10\n",
      "1814/1815 [============================>.] - ETA: 0s - loss: 0.2675 - acc: 0.8896\n",
      "Epoch 5: val_acc did not improve from 0.86131\n",
      "1815/1815 [==============================] - 46s 25ms/step - loss: 0.2675 - acc: 0.8896 - val_loss: 0.3263 - val_acc: 0.8605\n",
      "Epoch 6/10\n",
      "1813/1815 [============================>.] - ETA: 0s - loss: 0.2528 - acc: 0.8975\n",
      "Epoch 6: val_acc did not improve from 0.86131\n",
      "1815/1815 [==============================] - 47s 26ms/step - loss: 0.2528 - acc: 0.8975 - val_loss: 0.3340 - val_acc: 0.8613\n",
      "Epoch 7/10\n",
      "1814/1815 [============================>.] - ETA: 0s - loss: 0.2378 - acc: 0.9043\n",
      "Epoch 7: val_acc did not improve from 0.86131\n",
      "1815/1815 [==============================] - 47s 26ms/step - loss: 0.2378 - acc: 0.9043 - val_loss: 0.3304 - val_acc: 0.8612\n",
      "Epoch 7: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "embedding_dim = 100\n",
    "hidden_units = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim))\n",
    "model.add(LSTM(hidden_units))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(X_train, y_train, epochs=10, callbacks=[es, mc], batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fa8ccb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_predict(new_sentence):\n",
    "    new_sentence = re.sub(r'[^ã„±-ã…ã…-ã…£ê°€-í£ ]','', new_sentence)\n",
    "    new_sentence = okt.morphs(new_sentence, stem=True) # í† í°í™”\n",
    "    new_sentence = [word for word in new_sentence if not word in stopwords] # ë¶ˆìš©ì–´ ì œê±°\n",
    "    encoded = tokenizer.texts_to_sequences([new_sentence]) # ì •ìˆ˜ ì¸ì½”ë”©\n",
    "    pad_new = pad_sequences(encoded, maxlen = max_len) # íŒ¨ë”©\n",
    "    score = float(model.predict(pad_new)) # ì˜ˆì¸¡\n",
    "    if(score > 0.5):\n",
    "        print(\"{:.2f}% í™•ë¥ ë¡œ ê¸ì • ë¦¬ë·°ì…ë‹ˆë‹¤.\\n\".format(score * 100))\n",
    "    else:\n",
    "        print(\"{:.2f}% í™•ë¥ ë¡œ ë¶€ì • ë¦¬ë·°ì…ë‹ˆë‹¤.\\n\".format((1 - score) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8b0cc5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "60.85% í™•ë¥ ë¡œ ê¸ì • ë¦¬ë·°ì…ë‹ˆë‹¤.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentiment_predict('ã…‡ã…‚ìŸˆã…“ã…‡ã„´ã…')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cf7b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [t for d in train_x for t in d[0]]\n",
    "\n",
    "import nltk\n",
    "text = nltk.Text(tokens,name='NMSC')#nltkë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í†µí•´ì„œ í…ìŠ¤íŠ¸ ë°ì´í„° ë‚˜ì—´\n",
    "\n",
    "len(set(text.tokens))#35425ê°œì˜ ê³ ìœ  í…ìŠ¤íŠ¸ê°€ ì¡´ì¬\n",
    "\n",
    "text.vocab().most_common(20) #vocab().most_common(10) - í…ìŠ¤íŠ¸ ë¹ˆë„ ìƒìœ„ 10ê°œ ë³´ì—¬ì£¼ê¸° ì¦‰, count_values()ë¥¼ í†µí•´ì„œ ë‚´ë¦¼ì°¨ìˆœí•œ ê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a6b80095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>tags</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>yonki88</td>\n",
       "      <td>[]</td>\n",
       "      <td>ë‚˜ì˜ê·€ì—¼ë‘¥ì´!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>yonki88</td>\n",
       "      <td>[]</td>\n",
       "      <td>Fluffyë¥¼ ë‹¹ë‹¹íˆ ì‹œì¼œë¨¹ëŠ”ë‚˜ì´ ì´ì œì–´ë¦°ì´ë„¤ 20ê°œì›”</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>yonki88</td>\n",
       "      <td>['#ì´ëª¨ë“¤ê³¼', '#ëª¨ë¸ë°•ì°¬', '#ë‹¤ìŒì—ëŠ”']</td>\n",
       "      <td>ì†Œê°œìš¸ì œë¹µì†Œ ì¡°ìš©íˆ ë¨¹ì</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>yonki88</td>\n",
       "      <td>['#ì°¬ì´ê°€']</td>\n",
       "      <td>ìˆì–´ì„œ í–‰ë³µí•˜ë‹¤ ê·¼ë° ë½€ë½€í–ˆë”ë‹ˆ ì¹¨ì„ ì§ˆì§ˆí˜ë¦¬ê³ ìˆë„¤... ë‚´ì…ì— ë‹¤ ë¬»ì–´ ë¶€ë ¸ë‹¤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>yonki88</td>\n",
       "      <td>['#í”¼ë¶€ê³¼', '#í”¼ë¶€ë¯¸ìš©ì—']</td>\n",
       "      <td>ê°”ë‹¤ì™”ì–´ìš”ã…ã… ì‹ ê²½ì¨ì•¼ì§€ìš”</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>yonki88</td>\n",
       "      <td>['#ì•Œë§¥ìŠ¤ëœë“œâ›ºï¸', '#ë„ˆë„', '#ì‚¬ì¥ë‹˜']</td>\n",
       "      <td>ë‹¤ë¦¬ë¥¼ ê¼¬ì„ ìˆ˜ ìˆêµ¬ë‚˜ í¬ìŠ¤ ë°°ë¶€ë¥´ë‹ˆ ìŠ¬ìŠ¬ ì ì´ ì˜¤ì§€???ëŠ˜ì–´ì§€ëŠ” ëª¨ìŠµ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>yonki88</td>\n",
       "      <td>['#ë¯¸ë¦¬í¬ë¦¬ìŠ¤ë§ˆìŠ¤ğŸ„', '#ì˜¤ë«ë§Œì—']</td>\n",
       "      <td>ì…€ì¹´ë¿…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>yonki88</td>\n",
       "      <td>['#Newhipseat', '#ì–¼êµ´ì—', '#ì§œì¦ë‚˜ê¸°']</td>\n",
       "      <td>ìê¾¸ íŠ¸ëŸ¬ë¸”ë‚˜ì„œ í”¼ë¶€ê³¼ ê°”ë‹¤ì™”ë„¤ã…  ì¼ë³´ì§ì „</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>yonki88</td>\n",
       "      <td>['#ì°¬ì´', '#ìƒˆì˜·ì…ê³ ', '#ì•„ë¹ ']</td>\n",
       "      <td>í• ë¨¸ë‹ˆ ê¶Œì‚¬ì·¨ì„ì‹ë‚  ì´¬ì¹µ íŒ”ì•„í”„ë‹¤ ì–¸ëŠ¥ ê±·ì</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>yonki88</td>\n",
       "      <td>[]</td>\n",
       "      <td>ë‹¨ë‘˜ì´ ì§‘ì—ë‚¨ì•„.. ë‘˜ì´ ìŠ¤íƒ€ë²…ìŠ¤ê°€ëŠ”ê¸¸</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       id                              tags  \\\n",
       "0           0  yonki88                                []   \n",
       "1           1  yonki88                                []   \n",
       "2           2  yonki88       ['#ì´ëª¨ë“¤ê³¼', '#ëª¨ë¸ë°•ì°¬', '#ë‹¤ìŒì—ëŠ”']   \n",
       "3           3  yonki88                          ['#ì°¬ì´ê°€']   \n",
       "4           4  yonki88                ['#í”¼ë¶€ê³¼', '#í”¼ë¶€ë¯¸ìš©ì—']   \n",
       "5           5  yonki88       ['#ì•Œë§¥ìŠ¤ëœë“œâ›ºï¸', '#ë„ˆë„', '#ì‚¬ì¥ë‹˜']   \n",
       "6           6  yonki88            ['#ë¯¸ë¦¬í¬ë¦¬ìŠ¤ë§ˆìŠ¤ğŸ„', '#ì˜¤ë«ë§Œì—']   \n",
       "7           7  yonki88  ['#Newhipseat', '#ì–¼êµ´ì—', '#ì§œì¦ë‚˜ê¸°']   \n",
       "8           8  yonki88           ['#ì°¬ì´', '#ìƒˆì˜·ì…ê³ ', '#ì•„ë¹ ']   \n",
       "9           9  yonki88                                []   \n",
       "\n",
       "                                         content  \n",
       "0                                       ë‚˜ì˜ê·€ì—¼ë‘¥ì´!   \n",
       "1                Fluffyë¥¼ ë‹¹ë‹¹íˆ ì‹œì¼œë¨¹ëŠ”ë‚˜ì´ ì´ì œì–´ë¦°ì´ë„¤ 20ê°œì›”   \n",
       "2                                 ì†Œê°œìš¸ì œë¹µì†Œ ì¡°ìš©íˆ ë¨¹ì   \n",
       "3  ìˆì–´ì„œ í–‰ë³µí•˜ë‹¤ ê·¼ë° ë½€ë½€í–ˆë”ë‹ˆ ì¹¨ì„ ì§ˆì§ˆí˜ë¦¬ê³ ìˆë„¤... ë‚´ì…ì— ë‹¤ ë¬»ì–´ ë¶€ë ¸ë‹¤   \n",
       "4                                ê°”ë‹¤ì™”ì–´ìš”ã…ã… ì‹ ê²½ì¨ì•¼ì§€ìš”   \n",
       "5       ë‹¤ë¦¬ë¥¼ ê¼¬ì„ ìˆ˜ ìˆêµ¬ë‚˜ í¬ìŠ¤ ë°°ë¶€ë¥´ë‹ˆ ìŠ¬ìŠ¬ ì ì´ ì˜¤ì§€???ëŠ˜ì–´ì§€ëŠ” ëª¨ìŠµ   \n",
       "6                                           ì…€ì¹´ë¿…   \n",
       "7                       ìê¾¸ íŠ¸ëŸ¬ë¸”ë‚˜ì„œ í”¼ë¶€ê³¼ ê°”ë‹¤ì™”ë„¤ã…  ì¼ë³´ì§ì „   \n",
       "8                      í• ë¨¸ë‹ˆ ê¶Œì‚¬ì·¨ì„ì‹ë‚  ì´¬ì¹µ íŒ”ì•„í”„ë‹¤ ì–¸ëŠ¥ ê±·ì   \n",
       "9                         ë‹¨ë‘˜ì´ ì§‘ì—ë‚¨ì•„.. ë‘˜ì´ ìŠ¤íƒ€ë²…ìŠ¤ê°€ëŠ”ê¸¸   "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(BASE_DIR+'/crawlingyonki88.xlsx')\n",
    "df = df.fillna(0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e687b8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_regular_expression(text):\n",
    "    hangul = re.compile('[^ ã„±-ã…£ ê°€-í£]')  # í•œê¸€ ì¶”ì¶œ ê·œì¹™: ë„ì–´ ì“°ê¸°(1 ê°œ)ë¥¼ í¬í•¨í•œ í•œê¸€\n",
    "    result = hangul.sub('', text)  # ìœ„ì— ì„¤ì •í•œ \"hangul\"ê·œì¹™ì„ \"text\"ì— ì ìš©(.sub)ì‹œí‚´\n",
    "    return result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fe3d6c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ìˆì–´ì„œ í–‰ë³µí•˜ë‹¤ ê·¼ë° ë½€ë½€í–ˆë”ë‹ˆ ì¹¨ì„ ì§ˆì§ˆí˜ë¦¬ê³ ìˆë„¤ ë‚´ì…ì— ë‹¤ ë¬»ì–´ ë¶€ë ¸ë‹¤ '"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apply_regular_expression(df['content'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "112a617b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ë½€ë½€', 'ì¹¨', 'ì§ˆì§ˆ', 'ì…']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okt = Okt()  # ëª…ì‚¬ í˜•íƒœì†Œ ì¶”ì¶œ í•¨ìˆ˜\n",
    "nouns = okt.nouns(apply_regular_expression(df['content'][3]))\n",
    "nouns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "09218c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ë‚˜ì˜ê·€ì—¼ë‘¥ì´! Fluffyë¥¼ ë‹¹ë‹¹íˆ ì‹œì¼œë¨¹ëŠ”ë‚˜ì´ ì´ì œì–´ë¦°ì´ë„¤ 20ê°œì›” ì†Œê°œìš¸ì œë¹µì†Œ ì¡°ìš©íˆ ë¨¹ì ìˆì–´ì„œ í–‰ë³µí•˜ë‹¤ ê·¼ë° ë½€ë½€í–ˆë”ë‹ˆ ì¹¨ì„ ì§ˆì§ˆí˜ë¦¬ê³ ìˆë„¤... ë‚´ì…ì— ë‹¤ ë¬»ì–´ ë¶€ë ¸ë‹¤ ê°”ë‹¤ì™”ì–´ìš”ã…ã… ì‹ ê²½ì¨ì•¼ì§€ìš” ë‹¤ë¦¬ë¥¼ ê¼¬ì„ ìˆ˜ ìˆêµ¬ë‚˜ í¬ìŠ¤ ë°°ë¶€ë¥´ë‹ˆ ìŠ¬ìŠ¬ ì ì´ ì˜¤ì§€???ëŠ˜ì–´ì§€ëŠ” ëª¨ìŠµ ì…€ì¹´ë¿… ìê¾¸ íŠ¸ëŸ¬ë¸”ë‚˜ì„œ í”¼ë¶€ê³¼ ê°”ë‹¤ì™”ë„¤ã…  ì¼ë³´ì§ì „ í• ë¨¸ë‹ˆ ê¶Œì‚¬ì·¨ì„ì‹ë‚  ì´¬ì¹µ íŒ”ì•„í”„ë‹¤ ì–¸ëŠ¥ ê±·ì ë‹¨ë‘˜ì´ ì§‘ì—ë‚¨ì•„.. ë‘˜ì´ ìŠ¤íƒ€ë²…ìŠ¤ê°€ëŠ”ê¸¸ '"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = \"\".join(df['content'].tolist())\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "deeddf1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ë‚˜ì˜ê·€ì—¼ë‘¥ì´ ë¥¼ ë‹¹ë‹¹íˆ ì‹œì¼œë¨¹ëŠ”ë‚˜ì´ ì´ì œì–´ë¦°ì´ë„¤ ê°œì›” ì†Œê°œìš¸ì œë¹µì†Œ ì¡°ìš©íˆ ë¨¹ì ìˆì–´ì„œ í–‰ë³µí•˜ë‹¤ ê·¼ë° ë½€ë½€í–ˆë”ë‹ˆ ì¹¨ì„ ì§ˆì§ˆí˜ë¦¬ê³ ìˆë„¤ ë‚´ì…ì— ë‹¤ ë¬»ì–´ ë¶€ë ¸ë‹¤ ê°”ë‹¤ì™”ì–´ìš”ã…ã… ì‹ ê²½ì¨ì•¼ì§€ìš” ë‹¤ë¦¬ë¥¼ ê¼¬ì„ ìˆ˜ ìˆêµ¬ë‚˜ í¬ìŠ¤ ë°°ë¶€ë¥´ë‹ˆ ìŠ¬ìŠ¬ ì ì´ ì˜¤ì§€ëŠ˜ì–´ì§€ëŠ” ëª¨ìŠµ ì…€ì¹´ë¿… ìê¾¸ íŠ¸ëŸ¬ë¸”ë‚˜ì„œ í”¼ë¶€ê³¼ ê°”ë‹¤ì™”ë„¤ã…  ì¼ë³´ì§ì „ í• ë¨¸ë‹ˆ ê¶Œì‚¬ì·¨ì„ì‹ë‚  ì´¬ì¹µ íŒ”ì•„í”„ë‹¤ ì–¸ëŠ¥ ê±·ì ë‹¨ë‘˜ì´ ì§‘ì—ë‚¨ì•„ ë‘˜ì´ ìŠ¤íƒ€ë²…ìŠ¤ê°€ëŠ”ê¸¸ '"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apply_regular_expression(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0a53cf8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ë‚˜', 'ê·€ì—¼ë‘¥ì´', 'ë¥¼', 'ì–´ë¦°ì´', 'ê°œì›”', 'ì†Œê°œ', 'ì œë¹µ', 'ì†Œ', 'ë½€ë½€', 'ì¹¨', 'ì§ˆì§ˆ', 'ì…', 'ì‹ ê²½', 'ë‹¤ë¦¬', 'ê¼¬ì„', 'ìˆ˜', 'í¬ìŠ¤', 'ìŠ¬ìŠ¬', 'ì ', 'ì˜¤ì§€', 'ëª¨ìŠµ', 'ì…€ì¹´', 'ìê¾¸', 'íŠ¸ëŸ¬ë¸”', 'í”¼ë¶€', 'ì¼ë³´', 'ì§ì „', 'í• ë¨¸ë‹ˆ', 'ê¶Œ', 'ì·¨ì„ì‹', 'ë‚ ', 'ì´¬ì¹µ', 'íŒ”', 'ë‹¨ë‘˜', 'ì§‘', 'ë‚¨ì•„', 'ë‘˜', 'ìŠ¤íƒ€ë²…ìŠ¤']\n"
     ]
    }
   ],
   "source": [
    "nouns = okt.nouns(apply_regular_expression(corpus))\n",
    "print(nouns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7ca47fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "354d101e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ë‚˜', 1),\n",
       " ('ê·€ì—¼ë‘¥ì´', 1),\n",
       " ('ë¥¼', 1),\n",
       " ('ì–´ë¦°ì´', 1),\n",
       " ('ê°œì›”', 1),\n",
       " ('ì†Œê°œ', 1),\n",
       " ('ì œë¹µ', 1),\n",
       " ('ì†Œ', 1),\n",
       " ('ë½€ë½€', 1),\n",
       " ('ì¹¨', 1)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2d1e7a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ê·€ì—¼ë‘¥ì´', 1),\n",
       " ('ì–´ë¦°ì´', 1),\n",
       " ('ê°œì›”', 1),\n",
       " ('ì†Œê°œ', 1),\n",
       " ('ì œë¹µ', 1),\n",
       " ('ë½€ë½€', 1),\n",
       " ('ì§ˆì§ˆ', 1),\n",
       " ('ì‹ ê²½', 1),\n",
       " ('ë‹¤ë¦¬', 1),\n",
       " ('ê¼¬ì„', 1)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_counter = Counter({x: counter[x] for x in counter if len(x) > 1})\n",
    "available_counter.most_common(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1ec0aa91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['íœ´'],\n",
       " ['ì•„ì´êµ¬'],\n",
       " ['ì•„ì´ì¿ '],\n",
       " ['ì•„ì´ê³ '],\n",
       " ['ì–´'],\n",
       " ['ë‚˜'],\n",
       " ['ìš°ë¦¬'],\n",
       " ['ì €í¬'],\n",
       " ['ë”°ë¼'],\n",
       " ['ì˜í•´'],\n",
       " ['ì„'],\n",
       " ['ë¥¼'],\n",
       " ['ì—'],\n",
       " ['ì˜'],\n",
       " ['ê°€'],\n",
       " ['ìœ¼ë¡œ'],\n",
       " ['ë¡œ'],\n",
       " ['ì—ê²Œ'],\n",
       " ['ë¿ì´ë‹¤'],\n",
       " ['ì˜ê±°í•˜ì—¬'],\n",
       " ['ê·¼ê±°í•˜ì—¬'],\n",
       " ['ì…ê°í•˜ì—¬'],\n",
       " ['ê¸°ì¤€ìœ¼ë¡œ'],\n",
       " ['ì˜ˆí•˜ë©´'],\n",
       " ['ì˜ˆë¥¼ ë“¤ë©´'],\n",
       " ['ì˜ˆë¥¼ ë“¤ìë©´'],\n",
       " ['ì €'],\n",
       " ['ì†Œì¸'],\n",
       " ['ì†Œìƒ'],\n",
       " ['ì €í¬'],\n",
       " ['ì§€ë§ê³ '],\n",
       " ['í•˜ì§€ë§ˆ'],\n",
       " ['í•˜ì§€ë§ˆë¼'],\n",
       " ['ë‹¤ë¥¸'],\n",
       " ['ë¬¼ë¡ '],\n",
       " ['ë˜í•œ'],\n",
       " ['ê·¸ë¦¬ê³ '],\n",
       " ['ë¹„ê¸¸ìˆ˜ ì—†ë‹¤'],\n",
       " ['í•´ì„œëŠ” ì•ˆëœë‹¤'],\n",
       " ['ë¿ë§Œ ì•„ë‹ˆë¼'],\n",
       " ['ë§Œì´ ì•„ë‹ˆë‹¤'],\n",
       " ['ë§Œì€ ì•„ë‹ˆë‹¤'],\n",
       " ['ë§‰ë¡ í•˜ê³ '],\n",
       " ['ê´€ê³„ì—†ì´'],\n",
       " ['ê·¸ì¹˜ì§€ ì•Šë‹¤'],\n",
       " ['ê·¸ëŸ¬ë‚˜'],\n",
       " ['ê·¸ëŸ°ë°'],\n",
       " ['í•˜ì§€ë§Œ'],\n",
       " ['ë“ ê°„ì—'],\n",
       " ['ë…¼í•˜ì§€ ì•Šë‹¤'],\n",
       " ['ë”°ì§€ì§€ ì•Šë‹¤'],\n",
       " ['ì„¤ì‚¬'],\n",
       " ['ë¹„ë¡'],\n",
       " ['ë”ë¼ë„'],\n",
       " ['ì•„ë‹ˆë©´'],\n",
       " ['ë§Œ ëª»í•˜ë‹¤'],\n",
       " ['í•˜ëŠ” í¸ì´ ë‚«ë‹¤'],\n",
       " ['ë¶ˆë¬¸í•˜ê³ '],\n",
       " ['í–¥í•˜ì—¬'],\n",
       " ['í–¥í•´ì„œ'],\n",
       " ['í–¥í•˜ë‹¤'],\n",
       " ['ìª½ìœ¼ë¡œ'],\n",
       " ['í‹ˆíƒ€'],\n",
       " ['ì´ìš©í•˜ì—¬'],\n",
       " ['íƒ€ë‹¤'],\n",
       " ['ì˜¤ë¥´ë‹¤'],\n",
       " ['ì œì™¸í•˜ê³ '],\n",
       " ['ì´ ì™¸ì—'],\n",
       " ['ì´ ë°–ì—'],\n",
       " ['í•˜ì—¬ì•¼'],\n",
       " ['ë¹„ë¡œì†Œ'],\n",
       " ['í•œë‹¤ë©´ ëª°ë¼ë„'],\n",
       " ['ì™¸ì—ë„'],\n",
       " ['ì´ê³³'],\n",
       " ['ì—¬ê¸°'],\n",
       " ['ë¶€í„°'],\n",
       " ['ê¸°ì ìœ¼ë¡œ'],\n",
       " ['ë”°ë¼ì„œ'],\n",
       " ['í•  ìƒê°ì´ë‹¤'],\n",
       " ['í•˜ë ¤ê³ í•˜ë‹¤'],\n",
       " ['ì´ë¦¬í•˜ì—¬'],\n",
       " ['ê·¸ë¦¬í•˜ì—¬'],\n",
       " ['ê·¸ë ‡ê²Œ í•¨ìœ¼ë¡œì¨'],\n",
       " ['í•˜ì§€ë§Œ'],\n",
       " ['ì¼ë•Œ'],\n",
       " ['í• ë•Œ'],\n",
       " ['ì•ì—ì„œ'],\n",
       " ['ì¤‘ì—ì„œ'],\n",
       " ['ë³´ëŠ”ë°ì„œ'],\n",
       " ['ìœ¼ë¡œì¨'],\n",
       " ['ë¡œì¨'],\n",
       " ['ê¹Œì§€'],\n",
       " ['í•´ì•¼í•œë‹¤'],\n",
       " ['ì¼ê²ƒì´ë‹¤'],\n",
       " ['ë°˜ë“œì‹œ'],\n",
       " ['í• ì¤„ì•Œë‹¤'],\n",
       " ['í• ìˆ˜ìˆë‹¤'],\n",
       " ['í• ìˆ˜ìˆì–´'],\n",
       " ['ì„ì— í‹€ë¦¼ì—†ë‹¤'],\n",
       " ['í•œë‹¤ë©´'],\n",
       " ['ë“±'],\n",
       " ['ë“±ë“±'],\n",
       " ['ì œ'],\n",
       " ['ê²¨ìš°'],\n",
       " ['ë‹¨ì§€'],\n",
       " ['ë‹¤ë§Œ'],\n",
       " ['í• ë¿'],\n",
       " ['ë”©ë™'],\n",
       " ['ëŒ•ê·¸'],\n",
       " ['ëŒ€í•´ì„œ'],\n",
       " ['ëŒ€í•˜ì—¬'],\n",
       " ['ëŒ€í•˜ë©´'],\n",
       " ['í›¨ì”¬'],\n",
       " ['ì–¼ë§ˆë‚˜'],\n",
       " ['ì–¼ë§ˆë§Œí¼'],\n",
       " ['ì–¼ë§ˆí¼'],\n",
       " ['ë‚¨ì§“'],\n",
       " ['ì—¬'],\n",
       " ['ì–¼ë§ˆê°„'],\n",
       " ['ì•½ê°„'],\n",
       " ['ë‹¤ì†Œ'],\n",
       " ['ì¢€'],\n",
       " ['ì¡°ê¸ˆ'],\n",
       " ['ë‹¤ìˆ˜'],\n",
       " ['ëª‡'],\n",
       " ['ì–¼ë§ˆ'],\n",
       " ['ì§€ë§Œ'],\n",
       " ['í•˜ë¬¼ë©°'],\n",
       " ['ë˜í•œ'],\n",
       " ['ê·¸ëŸ¬ë‚˜'],\n",
       " ['ê·¸ë ‡ì§€ë§Œ'],\n",
       " ['í•˜ì§€ë§Œ'],\n",
       " ['ì´ì™¸ì—ë„'],\n",
       " ['ëŒ€í•´ ë§í•˜ìë©´'],\n",
       " ['ë¿ì´ë‹¤'],\n",
       " ['ë‹¤ìŒì—'],\n",
       " ['ë°˜ëŒ€ë¡œ'],\n",
       " ['ë°˜ëŒ€ë¡œ ë§í•˜ìë©´'],\n",
       " ['ì´ì™€ ë°˜ëŒ€ë¡œ'],\n",
       " ['ë°”ê¾¸ì–´ì„œ ë§í•˜ë©´'],\n",
       " ['ë°”ê¾¸ì–´ì„œ í•œë‹¤ë©´'],\n",
       " ['ë§Œì•½'],\n",
       " ['ê·¸ë ‡ì§€ì•Šìœ¼ë©´'],\n",
       " ['ê¹Œì•…'],\n",
       " ['íˆ­'],\n",
       " ['ë”±'],\n",
       " ['ì‚ê±±ê±°ë¦¬ë‹¤'],\n",
       " ['ë³´ë“œë“'],\n",
       " ['ë¹„ê±±ê±°ë¦¬ë‹¤'],\n",
       " ['ê½ˆë‹¹'],\n",
       " ['ì‘ë‹¹'],\n",
       " ['í•´ì•¼í•œë‹¤'],\n",
       " ['ì— ê°€ì„œ'],\n",
       " ['ê°'],\n",
       " ['ê°ê°'],\n",
       " ['ì—¬ëŸ¬ë¶„'],\n",
       " ['ê°ì¢…'],\n",
       " ['ê°ì'],\n",
       " ['ì œê°ê¸°'],\n",
       " ['í•˜ë„ë¡í•˜ë‹¤'],\n",
       " ['ì™€'],\n",
       " ['ê³¼'],\n",
       " ['ê·¸ëŸ¬ë¯€ë¡œ'],\n",
       " ['ê·¸ë˜ì„œ'],\n",
       " ['ê³ ë¡œ'],\n",
       " ['í•œ ê¹Œë‹­ì—'],\n",
       " ['í•˜ê¸° ë•Œë¬¸ì—'],\n",
       " ['ê±°ë‹ˆì™€'],\n",
       " ['ì´ì§€ë§Œ'],\n",
       " ['ëŒ€í•˜ì—¬'],\n",
       " ['ê´€í•˜ì—¬'],\n",
       " ['ê´€í•œ'],\n",
       " ['ê³¼ì—°'],\n",
       " ['ì‹¤ë¡œ'],\n",
       " ['ì•„ë‹ˆë‚˜ë‹¤ë¥¼ê°€'],\n",
       " ['ìƒê°í•œëŒ€ë¡œ'],\n",
       " ['ì§„ì§œë¡œ'],\n",
       " ['í•œì ì´ìˆë‹¤'],\n",
       " ['í•˜ê³¤í•˜ì˜€ë‹¤'],\n",
       " ['í•˜'],\n",
       " ['í•˜í•˜'],\n",
       " ['í—ˆí—ˆ'],\n",
       " ['ì•„í•˜'],\n",
       " ['ê±°ë°”'],\n",
       " ['ì™€'],\n",
       " ['ì˜¤'],\n",
       " ['ì™œ'],\n",
       " ['ì–´ì§¸ì„œ'],\n",
       " ['ë¬´ì—‡ë•Œë¬¸ì—'],\n",
       " ['ì–´ì°Œ'],\n",
       " ['í•˜ê² ëŠ”ê°€'],\n",
       " ['ë¬´ìŠ¨'],\n",
       " ['ì–´ë””'],\n",
       " ['ì–´ëŠê³³'],\n",
       " ['ë”êµ°ë‹¤ë‚˜'],\n",
       " ['í•˜ë¬¼ë©°'],\n",
       " ['ë”ìš±ì´ëŠ”'],\n",
       " ['ì–´ëŠë•Œ'],\n",
       " ['ì–¸ì œ'],\n",
       " ['ì•¼']]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = pd.read_csv(\"https://raw.githubusercontent.com/yoonkt200/FastCampusDataset/master/korean_stopwords.txt\").values.tolist()\n",
    "stopwords[:200]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a9ccd23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def text_cleaning(text):\n",
    "    hangul = re.compile('[^ ã„±-ã…£ ê°€-í£]')  # ì •ê·œ í‘œí˜„ì‹ ì²˜ë¦¬\n",
    "    result = hangul.sub('', text)\n",
    "    okt = Okt()  # í˜•íƒœì†Œ ì¶”ì¶œ\n",
    "    nouns = okt.nouns(result)\n",
    "    nouns = [x for x in nouns if len(x) > 1]  # í•œê¸€ì í‚¤ì›Œë“œ ì œê±°\n",
    "    nouns = [x for x in nouns if x not in stopwords]  # ë¶ˆìš©ì–´ ì œê±°\n",
    "    return nouns\n",
    "\n",
    "vect = CountVectorizer(tokenizer = lambda x: text_cleaning(x))\n",
    "bow_vect = vect.fit_transform(df['content'].tolist())\n",
    "word_list = vect.get_feature_names()\n",
    "count_list = bow_vect.toarray().sum(axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "032624ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ê°œì›”',\n",
       " 'ê·€ì—¼ë‘¥ì´',\n",
       " 'ê¼¬ì„',\n",
       " 'ë‚¨ì•„',\n",
       " 'ë‹¤ë¦¬',\n",
       " 'ë‹¨ë‘˜',\n",
       " 'ëª¨ìŠµ',\n",
       " 'ë½€ë½€',\n",
       " 'ì…€ì¹´',\n",
       " 'ì†Œê°œ',\n",
       " 'ìŠ¤íƒ€ë²…ìŠ¤',\n",
       " 'ìŠ¬ìŠ¬',\n",
       " 'ì‹ ê²½',\n",
       " 'ì–´ë¦°ì´',\n",
       " 'ì˜¤ì§€',\n",
       " 'ì¼ë³´',\n",
       " 'ìê¾¸',\n",
       " 'ì œë¹µ',\n",
       " 'ì§ì „',\n",
       " 'ì§ˆì§ˆ',\n",
       " 'ì´¬ì¹µ',\n",
       " 'ì·¨ì„ì‹',\n",
       " 'íŠ¸ëŸ¬ë¸”',\n",
       " 'í¬ìŠ¤',\n",
       " 'í”¼ë¶€',\n",
       " 'í• ë¨¸ë‹ˆ']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "afa71859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c45f2af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ê°œì›”': 1,\n",
       " 'ê·€ì—¼ë‘¥ì´': 1,\n",
       " 'ê¼¬ì„': 1,\n",
       " 'ë‚¨ì•„': 1,\n",
       " 'ë‹¤ë¦¬': 1,\n",
       " 'ë‹¨ë‘˜': 1,\n",
       " 'ëª¨ìŠµ': 1,\n",
       " 'ë½€ë½€': 1,\n",
       " 'ì…€ì¹´': 1,\n",
       " 'ì†Œê°œ': 1,\n",
       " 'ìŠ¤íƒ€ë²…ìŠ¤': 1,\n",
       " 'ìŠ¬ìŠ¬': 1,\n",
       " 'ì‹ ê²½': 1,\n",
       " 'ì–´ë¦°ì´': 1,\n",
       " 'ì˜¤ì§€': 1,\n",
       " 'ì¼ë³´': 1,\n",
       " 'ìê¾¸': 1,\n",
       " 'ì œë¹µ': 1,\n",
       " 'ì§ì „': 1,\n",
       " 'ì§ˆì§ˆ': 1,\n",
       " 'ì´¬ì¹µ': 1,\n",
       " 'ì·¨ì„ì‹': 1,\n",
       " 'íŠ¸ëŸ¬ë¸”': 1,\n",
       " 'í¬ìŠ¤': 1,\n",
       " 'í”¼ë¶€': 1,\n",
       " 'í• ë¨¸ë‹ˆ': 1}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_dict = dict(zip(word_list, count_list))\n",
    "word_count_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2cff1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
